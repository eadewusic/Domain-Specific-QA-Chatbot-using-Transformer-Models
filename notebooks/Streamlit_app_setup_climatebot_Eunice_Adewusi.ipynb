{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **[Streamlit Setup] AyikaBot - Generative QA Chatbot for Climate Education**\n",
        "\n",
        "This project sets up and tests a climate-focused Q&A chatbot using a fine-tuned pre-trained T5 model. It uses Streamlit for the web interface and ngrok for tunneling the local app online from Google Colab. I did this because it is ideal for testing before deploying to Streamlit Cloud.\n",
        "\n",
        "#### **Features:**\n",
        "- Loads a custom fine-tuned T5 model for climate education Q&A.\n",
        "- Runs a Streamlit app to interact with the chatbot.\n",
        "- Uses ngrok to generate a public link for live testing from Google Colab.\n",
        "\n",
        "#### **Useful Links:**\n",
        "- Checkout more about the project here: https://github.com/eadewusic/Domain-Specific-QA-Chatbot-using-Transformer-Models\n",
        "- You can also find the fine-tuned pretrained model and other files here: https://huggingface.co/Climi/Climate-Education-QA-Chatbot\n",
        "\n",
        "**Author:** Eunice Adewusi\n",
        "\n",
        "**Date:** June 2025"
      ],
      "metadata": {
        "id": "6lbxlZF-YfHF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit\n",
        "!pip install pyngrok"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQ_jp55pWLuz",
        "outputId": "0d50c188-fd5c-4752-889e-d50645ffbad1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.46.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.2.1)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.2.1)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.1.2)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.14.0)\n",
            "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.24.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.43.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.6.15)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.25.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Downloading streamlit-1.46.0-py3-none-any.whl (10.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m86.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m99.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: watchdog, pydeck, streamlit\n",
            "Successfully installed pydeck-0.9.1 streamlit-1.46.0 watchdog-6.0.0\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.11-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n",
            "Downloading pyngrok-7.2.11-py3-none-any.whl (25 kB)\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-7.2.11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Using ngrok tunnel\n",
        "!npm install -g localtunnel"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4O_UogSXWSHN",
        "outputId": "b92b2347-7718-4c2c-f658-438cd1d42e1a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K\n",
            "added 22 packages in 5s\n",
            "\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K\n",
            "\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K3 packages are looking for funding\n",
            "\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K  run `npm fund` for details\n",
            "\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import streamlit as st\n",
        "import time\n",
        "import re\n",
        "from typing import Tuple, List, Optional\n",
        "import sys\n",
        "import os\n",
        "import subprocess\n",
        "import threading\n",
        "import time\n",
        "import requests\n",
        "from transformers import T5Tokenizer, TFT5ForConditionalGeneration"
      ],
      "metadata": {
        "id": "ejX6GKLlX6Cn"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set ngrok authentication token\n",
        "from pyngrok import ngrok\n",
        "ngrok.set_auth_token(\"insert_your_auth_key_from_ngrok_site\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UXA6IZFb6Ta_",
        "outputId": "abb0542e-f588-42c3-c77a-ac86d3559750"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": []
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the correct tunnel password from loca.lt\n",
        "# this is needed for ngrok to host the app\n",
        "password = requests.get(\"https://loca.lt/mytunnelpassword\").text.strip()\n",
        "print(f\"\\n Tunnel Password: {password}\\n\")"
      ],
      "metadata": {
        "id": "PmOt9sRpTTP8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- When this cell is run, the output displays something like \"Tunnel Password: ##.###.##.###\" (where # is an actual digit)\n",
        "\n",
        "- Input that in the custom ngrok page (you'll get a link from the last cell in this notebook) for your app to run\n",
        "\n",
        "Hiding mine :)"
      ],
      "metadata": {
        "id": "V46nFXCLSwG1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# check folder content\n",
        "!ls /content/climate_chatbot_BEST_exp4c"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DlJOh7smD0lt",
        "outputId": "3337c7e7-3a25-4e0a-aaa3-6f60444ed06a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "added_tokens.json\t       generation_config.json\tspiece.model\n",
            "ARCHITECTURE.md\t\t       model_architecture.json\ttf_model.h5\n",
            "ayikabot_complete_pipeline.py  optimal_generation.py\ttokenizer_config.json\n",
            "comprehensive_results.json     run_chatbot.py\n",
            "config.json\t\t       special_tokens_map.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the best fine-tuned pre-trained T5 model and tokenizer\n",
        "model = TFT5ForConditionalGeneration.from_pretrained(\"/content/climate_chatbot_BEST_exp4c\")\n",
        "tokenizer = T5Tokenizer.from_pretrained(\"/content/climate_chatbot_BEST_exp4c\")\n",
        "\n",
        "# Save loaded model and tokenizer to a new directory\n",
        "model.save_pretrained(\"/content/ayikabot_clean\")\n",
        "tokenizer.save_pretrained(\"/content/ayikabot_clean\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zUXNgah7PScT",
        "outputId": "1b64f98e-b7f4-40a5-940b-8be8e5e6bfb9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFT5ForConditionalGeneration.\n",
            "\n",
            "All the layers of TFT5ForConditionalGeneration were initialized from the model checkpoint at /content/climate_chatbot_BEST_exp4c.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/ayikabot_clean/tokenizer_config.json',\n",
              " '/content/ayikabot_clean/special_tokens_map.json',\n",
              " '/content/ayikabot_clean/spiece.model',\n",
              " '/content/ayikabot_clean/added_tokens.json')"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can also find the fine-tuned pretrained model and other files here: https://huggingface.co/Climi/Climate-Education-QA-Chatbot"
      ],
      "metadata": {
        "id": "Oj-UV9b6UMql"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This was done to get a more focused and clean directory with the very important files for deployment"
      ],
      "metadata": {
        "id": "Iz-mvcnKO7Wq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The \"/content/ayikabot_streamlit_app.py\" file contains all the code needed for streamlit to run.\n",
        "# Whatever is to be changed on the UI should be changed in this file\n",
        "def run_streamlit():\n",
        "    with open(\"streamlit_log.txt\", \"w\") as f:\n",
        "        subprocess.run(\n",
        "            [\"streamlit\", \"run\", \"/content/ayikabot_streamlit_app.py\", \"--server.port\", \"8501\", \"--server.headless\", \"true\"],\n",
        "            stdout=f,\n",
        "            stderr=subprocess.STDOUT\n",
        "        )\n",
        "\n",
        "# Start Streamlit in a background thread\n",
        "streamlit_thread = threading.Thread(target=run_streamlit)\n",
        "streamlit_thread.start()\n",
        "\n",
        "# Wait for Streamlit to boot up fully\n",
        "print(\"Waiting for Streamlit to start...\")\n",
        "time.sleep(20)  # Increased wait time to 20 seconds for larger applications\n",
        "\n",
        "# Kill any existing ngrok tunnels before starting a new one\n",
        "print(\"Killing any existing ngrok tunnels...\")\n",
        "ngrok.kill()\n",
        "time.sleep(5) # Give ngrok time to shut down\n",
        "\n",
        "# Now start ngrok tunnel AFTER Streamlit is fully running\n",
        "try:\n",
        "    print(\"Starting new ngrok tunnel...\")\n",
        "    public_url = ngrok.connect(8501).public_url # Access the public_url attribute\n",
        "    print(f\"App is live at: {public_url}\")\n",
        "except Exception as e:\n",
        "    print(f\"Failed to start ngrok tunnel: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x107T-uMJt2g",
        "outputId": "a0bbe1c5-6f65-4ea2-c9a8-105b2b0bd9c1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Waiting for Streamlit to start...\n",
            "Killing any existing ngrok tunnels...\n",
            "Starting new ngrok tunnel...\n",
            "App is live at: https://02a0-34-125-57-200.ngrok-free.app\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The streamlit app link is https://02a0-34-125-57-200.ngrok-free.app\n",
        "\n",
        "This still needs to be deployed because the generated public URL becomes invalid when Colab runtime stops, as the ngrok tunnel closes. I used this approach to test the code and functionalities before deploying to Streamlit Cloud"
      ],
      "metadata": {
        "id": "89lgPDAmWGhV"
      }
    }
  ]
}